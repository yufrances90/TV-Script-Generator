{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "i.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kyuHNH2gO4b",
        "colab_type": "text"
      },
      "source": [
        "# 1. Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCgQckobgO4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import helper\n",
        "# import problem_unittests as tests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMa3EQndgmKu",
        "colab_type": "code",
        "outputId": "4b81df7f-77f2-463e-cbc6-3cffdf4f5e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU0EIV4Hij3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SPECIAL_WORDS = {'PADDING': '<PAD>'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LSlg_Z-gO4v",
        "colab_type": "text"
      },
      "source": [
        "# 2. Explore the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M83fuYuhyhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(path):\n",
        "    \"\"\"\n",
        "    Load Dataset from File\n",
        "    \"\"\"\n",
        "    input_file = os.path.join(path)\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGM_GDt5iO1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_and_save_data(dataset_path, token_lookup, create_lookup_tables):\n",
        "    \"\"\"\n",
        "    Preprocess Text Data\n",
        "    \"\"\"\n",
        "    text = load_data(dataset_path)\n",
        "    \n",
        "    # Ignore notice, since we don't use it for analysing the data\n",
        "    text = text[81:]\n",
        "\n",
        "    token_dict = token_lookup()\n",
        "    for key, token in token_dict.items():\n",
        "        text = text.replace(key, ' {} '.format(token))\n",
        "\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "\n",
        "    vocab_to_int, int_to_vocab = create_lookup_tables(text + list(SPECIAL_WORDS.values()))\n",
        "    int_text = [vocab_to_int[word] for word in text]\n",
        "    pickle.dump((int_text, vocab_to_int, int_to_vocab, token_dict), open('gdrive/My Drive/Lab/preprocess.p', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwo1eoaEiwHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_preprocess():\n",
        "    \"\"\"\n",
        "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
        "    \"\"\"\n",
        "    return pickle.load(open('gdrive/My Drive/Lab/preprocess.p', mode='rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZF87z9ZjO44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(filename, decoder):\n",
        "    torch.save({'state_dict': decoder.state_dict()}, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs1RuUTQD4Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(filename):\n",
        "    return torch.load(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U516D_QlgO42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'gdrive/My Drive/Lab/data/Seinfeld_Scripts.txt'\n",
        "text = load_data(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XSjkzP9gO5C",
        "colab_type": "code",
        "outputId": "86f42453-8080-4521-c3b1-fcd64f804e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "view_line_range = (0, 10)\n",
        "\n",
        "print('Dataset Stats')\n",
        "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
        "\n",
        "lines = text.split('\\n')\n",
        "print('Number of lines: {}'.format(len(lines)))\n",
        "word_count_line = [len(line.split()) for line in lines]\n",
        "print('Average number of words in each line: {}'.format(np.average(word_count_line)))\n",
        "\n",
        "print()\n",
        "print('The lines {} to {}:'.format(*view_line_range))\n",
        "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Stats\n",
            "Roughly the number of unique words: 46367\n",
            "Number of lines: 109233\n",
            "Average number of words in each line: 5.544240293684143\n",
            "\n",
            "The lines 0 to 10:\n",
            "jerry: do you know what this is all about? do you know, why were here? to be out, this is out...and out is one of the single most enjoyable experiences of life. people...did you ever hear people talking about we should go out? this is what theyre talking about...this whole thing, were all out now, no one is home. not one person here is home, were all out! there are people trying to find us, they dont know where we are. (on an imaginary phone) did you ring?, i cant find him. where did he go? he didnt tell me where he was going. he must have gone out. you wanna go out you get ready, you pick out the clothes, right? you take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...then youre standing around, what do you do? you go we gotta be getting back. once youre out, you wanna get back! you wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? where ever you are in life, its my feeling, youve gotta go. \n",
            "\n",
            "jerry: (pointing at georges shirt) see, to me, that button is in the worst possible spot. the second button literally makes or breaks the shirt, look at it. its too high! its in no-mans-land. you look like you live with your mother. \n",
            "\n",
            "george: are you through? \n",
            "\n",
            "jerry: you do of course try on, when you buy? \n",
            "\n",
            "george: yes, it was purple, i liked it, i dont actually recall considering the buttons. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMZ6xJoYgO5R",
        "colab_type": "text"
      },
      "source": [
        "# 3. Implement Pre-processing Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_HCdCzDgO5S",
        "colab_type": "text"
      },
      "source": [
        "### Lookup Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH2DNdwGgO5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_lookup_tables(text):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    :param text: The text of tv scripts split into words\n",
        "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
        "    \"\"\"\n",
        "    \n",
        "    vocab_to_int = dict()\n",
        "    int_to_vocab = dict()\n",
        "    \n",
        "    sorted_word_set = sorted(set(text))\n",
        "    \n",
        "    for i, word in enumerate(sorted_word_set):\n",
        "        vocab_to_int[word] = i\n",
        "        int_to_vocab[i] = word\n",
        "    \n",
        "    return (vocab_to_int, int_to_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQXrG9uAgO5f",
        "colab_type": "code",
        "outputId": "f17d9b35-3c5b-4418-c63a-6668c4b33fc8",
        "colab": {}
      },
      "source": [
        "tests.test_create_lookup_tables(create_lookup_tables)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxzvAd5rgO5r",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYD7Qf70gO5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def token_lookup():\n",
        "    \"\"\"\n",
        "    Generate a dict to turn punctuation into a token.\n",
        "    :return: Tokenized dictionary where the key is the punctuation and the value is the token\n",
        "    \"\"\"\n",
        "    token_dict = dict()\n",
        "    \n",
        "    punctuation_list = [\n",
        "        '.', \n",
        "        ',', \n",
        "        '\"', \n",
        "        ';', \n",
        "        '!', \n",
        "        '?', \n",
        "        '(', \n",
        "        ')',\n",
        "        '-',\n",
        "        '\\n'\n",
        "    ]\n",
        "    \n",
        "    token_list = [\n",
        "        '||Period||', \n",
        "        '||Comma||', \n",
        "        '||Quotation_Mark||', \n",
        "        '||Semicolon||', \n",
        "        '||Exclamation_Mark||', \n",
        "        '||Question_Mark||', \n",
        "        '||Left_Parentheses||', \n",
        "        '||Right_Parentheses||', \n",
        "        '||Dash||', \n",
        "        '||Return||'\n",
        "    ]\n",
        "    \n",
        "    for (punctuation, token) in zip(punctuation_list, token_list):\n",
        "        token_dict[punctuation] = token\n",
        "        \n",
        "    return token_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMSDBfGXgO50",
        "colab_type": "code",
        "outputId": "3bc34a9f-4255-4e94-a374-c989867b755c",
        "colab": {}
      },
      "source": [
        "tests.test_tokenize(token_lookup)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niBXV40EgO58",
        "colab_type": "text"
      },
      "source": [
        "## Pre-process & Save Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT6LRcoIgO5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L3nJN2bgO6G",
        "colab_type": "text"
      },
      "source": [
        "# **************** #1 Check Point ****************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5HuaioygO6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_text, vocab_to_int, int_to_vocab, token_dict = load_preprocess()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URxy4KAmgO6N",
        "colab_type": "text"
      },
      "source": [
        "### Check Access to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvnuuJZVgO6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "    print('No GPU found. Please use a GPU to train your neural network.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cG8j4K-gO6Y",
        "colab_type": "text"
      },
      "source": [
        "### Batch Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvScOkgJgO6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_data(words, sequence_length, batch_size):\n",
        "    \"\"\"\n",
        "    Batch the neural network data using DataLoader\n",
        "    :param words: The word ids of the TV scripts\n",
        "    :param sequence_length: The sequence length of each batch\n",
        "    :param batch_size: The size of each batch; the number of sequences in a batch\n",
        "    :return: DataLoader with batched data\n",
        "    \"\"\"\n",
        "    \n",
        "    ###\n",
        "    \n",
        "    words_len = len(words)\n",
        "    \n",
        "    batch_size_total = batch_size * sequence_length\n",
        "    \n",
        "    n_batches = words_len // batch_size_total\n",
        "    \n",
        "    words = words[:n_batches * batch_size_total]\n",
        "    \n",
        "    x,y = [],[]\n",
        "    \n",
        "    for idx in range(0,len(words) - sequence_length):\n",
        "        x.append(words[idx:idx + sequence_length])\n",
        "        y.append(words[idx+sequence_length])\n",
        "        \n",
        "    feature_arr = np.asarray(x)\n",
        "    target_arr = np.asarray(y)\n",
        "        \n",
        "    ###\n",
        "    \n",
        "    feature_tensors = torch.from_numpy(feature_arr)\n",
        "    target_tensors = torch.from_numpy(target_arr)\n",
        "    \n",
        "    ###\n",
        "    \n",
        "    data = TensorDataset(feature_tensors, target_tensors)\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        data, \n",
        "        shuffle=True,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "        \n",
        "        \n",
        "    return data_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO6fBrxZgO6j",
        "colab_type": "code",
        "outputId": "768a99d8-a595-40b4-9900-718566003e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "test_text = range(50)\n",
        "t_loader = batch_data(test_text, sequence_length=5, batch_size=2)\n",
        "\n",
        "data_iter = iter(t_loader)\n",
        "sample_x, sample_y = data_iter.next()\n",
        "\n",
        "print(sample_x.shape)\n",
        "print(sample_x)\n",
        "print()\n",
        "print(sample_y.shape)\n",
        "print(sample_y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5])\n",
            "tensor([[26, 27, 28, 29, 30],\n",
            "        [24, 25, 26, 27, 28]])\n",
            "\n",
            "torch.Size([2])\n",
            "tensor([31, 29])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcVKegk7gO6q",
        "colab_type": "text"
      },
      "source": [
        "# 4. Build the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GorXQeoBgO6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the PyTorch RNN Module\n",
        "        :param vocab_size: The number of input dimensions of the neural network (the size of the vocabulary)\n",
        "        :param output_size: The number of output dimensions of the neural network\n",
        "        :param embedding_dim: The size of embeddings, should you choose to use them        \n",
        "        :param hidden_dim: The size of the hidden layer outputs\n",
        "        :param dropout: dropout to add in between LSTM/GRU layers\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        # set class variables\n",
        "        self.input_dim = vocab_size\n",
        "        self.output_dim = output_size\n",
        "        self.n_hidden = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        # define model layers\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim, \n",
        "            hidden_dim, \n",
        "            batch_first=True, \n",
        "            num_layers=n_layers,\n",
        "            dropout=dropout)\n",
        "        self.linear = nn.Linear(hidden_dim, output_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden\n",
        "    \n",
        "    def forward(self, nn_input, hidden):\n",
        "        \"\"\"\n",
        "        Forward propagation of the neural network\n",
        "        :param nn_input: The input to the neural network\n",
        "        :param hidden: The hidden state        \n",
        "        :return: Two Tensors, the output of the neural network and the latest hidden state\n",
        "        \"\"\"\n",
        "        \n",
        "        batch_size = nn_input.size(0)\n",
        "        \n",
        "        embeds = self.embeddings(nn_input)\n",
        "        \n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        \n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        \n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.n_hidden)\n",
        "        \n",
        "        output = self.linear(lstm_out)\n",
        "        \n",
        "        output = output.view(batch_size, -1, self.output_dim)\n",
        "        \n",
        "        out = output[:, -1]\n",
        "        \n",
        "        return out, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY5xiWrJgO6y",
        "colab_type": "code",
        "outputId": "44fea252-2fbf-43df-b3e7-855ca97b43f5",
        "colab": {}
      },
      "source": [
        "tests.test_rnn(RNN, train_on_gpu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38jN5u20gO64",
        "colab_type": "text"
      },
      "source": [
        "### Define forward and backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaIsdM4lgO66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
        "    \"\"\"\n",
        "    Forward and backward propagation on the neural network\n",
        "    :param rnn: The PyTorch Module that holds the neural network\n",
        "    :param optimizer: The PyTorch optimizer for the neural network\n",
        "    :param criterion: The PyTorch loss function\n",
        "    :param inp: A batch of input to the neural network\n",
        "    :param target: The target output for the batch of input\n",
        "    :return: The loss and the latest hidden state Tensor\n",
        "    \"\"\"\n",
        "    \n",
        "    if train_on_gpu:\n",
        "        inp, target = inp.cuda(), target.cuda()\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    hidden = tuple([each.data for each in hidden])\n",
        "    \n",
        "    # zero accumulated gradients\n",
        "    rnn.zero_grad()\n",
        "    \n",
        "    # get the output from the model\n",
        "    output, hidden = rnn(inp, hidden)\n",
        "    \n",
        "    # calculate the loss and perform backprop\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "     \n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss.item(), hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzBxFizHgO6_",
        "colab_type": "code",
        "outputId": "d60ae0eb-48f3-4f6d-e592-d31e10d2e706",
        "colab": {}
      },
      "source": [
        "tests.test_forward_back_prop(RNN, forward_back_prop, train_on_gpu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4eWESkZgO7F",
        "colab_type": "text"
      },
      "source": [
        "# 5. Neural Network Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE2iCyuPgO7H",
        "colab_type": "text"
      },
      "source": [
        "### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH4wn49ugO7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
        "    batch_losses = []\n",
        "    \n",
        "    rnn.train()\n",
        "\n",
        "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
        "    for epoch_i in range(1, n_epochs + 1):\n",
        "        \n",
        "        # initialize hidden state\n",
        "        hidden = rnn.init_hidden(batch_size)\n",
        "        \n",
        "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "            \n",
        "            # make sure you iterate over completely full batches, only\n",
        "            n_batches = len(train_loader.dataset)//batch_size\n",
        "            if(batch_i > n_batches):\n",
        "                break\n",
        "            \n",
        "            # forward, back prop\n",
        "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
        "            # record loss\n",
        "            batch_losses.append(loss)\n",
        "\n",
        "            # printing loss stats\n",
        "            if batch_i % show_every_n_batches == 0:\n",
        "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
        "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
        "                batch_losses = []\n",
        "\n",
        "    # returns a trained rnn\n",
        "    return rnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_HwJ90xgO7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data params\n",
        "# Sequence Length\n",
        "sequence_length = 20  # of words in a sequence\n",
        "# Batch Size\n",
        "batch_size = 256\n",
        "\n",
        "# data loader - do not change\n",
        "train_loader = batch_data(int_text, sequence_length, batch_size)\n",
        "\n",
        "# Training parameters\n",
        "# Number of Epochs\n",
        "num_epochs = 50\n",
        "# Learning Rate\n",
        "learning_rate = 0.0005\n",
        "\n",
        "# Model parameters\n",
        "# Vocab size\n",
        "vocab_size = len(vocab_to_int)\n",
        "# Output size\n",
        "output_size = vocab_size\n",
        "# Embedding Dimension\n",
        "embedding_dim = 250\n",
        "# Hidden Dimension\n",
        "hidden_dim = 500\n",
        "# Number of RNN Layers\n",
        "n_layers = 3\n",
        "\n",
        "# Show stats for every n number of batches\n",
        "show_every_n_batches = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Icex5HKgO7X",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZffH_HvygO7Z",
        "colab_type": "code",
        "outputId": "234be02f-8096-4ea2-c7db-9bd0ddaf23e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
        "if train_on_gpu:\n",
        "    rnn.cuda()\n",
        "\n",
        "# defining loss and optimization functions for training\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# training the model\n",
        "trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
        "\n",
        "# saving the trained model\n",
        "save_model('gdrive/My Drive/Lab/save/trained_rnn_6.pt', trained_rnn)\n",
        "print('Model Trained and Saved')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 50 epoch(s)...\n",
            "Epoch:    1/50    Loss: 5.698985152244568\n",
            "\n",
            "Epoch:    1/50    Loss: 4.964480973243713\n",
            "\n",
            "Epoch:    1/50    Loss: 4.740882186889649\n",
            "\n",
            "Epoch:    1/50    Loss: 4.6329581823348995\n",
            "\n",
            "Epoch:    1/50    Loss: 4.549121007919312\n",
            "\n",
            "Epoch:    1/50    Loss: 4.482640533924103\n",
            "\n",
            "Epoch:    2/50    Loss: 4.382505394952168\n",
            "\n",
            "Epoch:    2/50    Loss: 4.299875299453736\n",
            "\n",
            "Epoch:    2/50    Loss: 4.293565891265869\n",
            "\n",
            "Epoch:    2/50    Loss: 4.2621288142204286\n",
            "\n",
            "Epoch:    2/50    Loss: 4.233452224731446\n",
            "\n",
            "Epoch:    2/50    Loss: 4.21147004365921\n",
            "\n",
            "Epoch:    3/50    Loss: 4.165682610501064\n",
            "\n",
            "Epoch:    3/50    Loss: 4.1186776638031\n",
            "\n",
            "Epoch:    3/50    Loss: 4.1119798293113705\n",
            "\n",
            "Epoch:    3/50    Loss: 4.090079281330109\n",
            "\n",
            "Epoch:    3/50    Loss: 4.086628966808319\n",
            "\n",
            "Epoch:    3/50    Loss: 4.096794985771179\n",
            "\n",
            "Epoch:    4/50    Loss: 4.044210959990738\n",
            "\n",
            "Epoch:    4/50    Loss: 4.010049983024597\n",
            "\n",
            "Epoch:    4/50    Loss: 3.996075800895691\n",
            "\n",
            "Epoch:    4/50    Loss: 3.9749385418891907\n",
            "\n",
            "Epoch:    4/50    Loss: 3.9920443778038024\n",
            "\n",
            "Epoch:    4/50    Loss: 3.9802807989120486\n",
            "\n",
            "Epoch:    5/50    Loss: 3.9344851734445823\n",
            "\n",
            "Epoch:    5/50    Loss: 3.9089804005622866\n",
            "\n",
            "Epoch:    5/50    Loss: 3.9062246751785277\n",
            "\n",
            "Epoch:    5/50    Loss: 3.918899317741394\n",
            "\n",
            "Epoch:    5/50    Loss: 3.9233668746948243\n",
            "\n",
            "Epoch:    5/50    Loss: 3.885198642253876\n",
            "\n",
            "Epoch:    6/50    Loss: 3.85436250459673\n",
            "\n",
            "Epoch:    6/50    Loss: 3.8182777218818664\n",
            "\n",
            "Epoch:    6/50    Loss: 3.8445824832916258\n",
            "\n",
            "Epoch:    6/50    Loss: 3.848017882347107\n",
            "\n",
            "Epoch:    6/50    Loss: 3.837953773498535\n",
            "\n",
            "Epoch:    6/50    Loss: 3.845791060447693\n",
            "\n",
            "Epoch:    7/50    Loss: 3.79483551243596\n",
            "\n",
            "Epoch:    7/50    Loss: 3.7942579288482667\n",
            "\n",
            "Epoch:    7/50    Loss: 3.7682142534255982\n",
            "\n",
            "Epoch:    7/50    Loss: 3.7861715092658996\n",
            "\n",
            "Epoch:    7/50    Loss: 3.7813767499923707\n",
            "\n",
            "Epoch:    7/50    Loss: 3.793540829181671\n",
            "\n",
            "Epoch:    8/50    Loss: 3.753374348134868\n",
            "\n",
            "Epoch:    8/50    Loss: 3.7240995359420777\n",
            "\n",
            "Epoch:    8/50    Loss: 3.7362397170066832\n",
            "\n",
            "Epoch:    8/50    Loss: 3.7421218061447146\n",
            "\n",
            "Epoch:    8/50    Loss: 3.7327011399269105\n",
            "\n",
            "Epoch:    8/50    Loss: 3.7369580273628236\n",
            "\n",
            "Epoch:    9/50    Loss: 3.704927829483313\n",
            "\n",
            "Epoch:    9/50    Loss: 3.6795866684913636\n",
            "\n",
            "Epoch:    9/50    Loss: 3.6919151186943053\n",
            "\n",
            "Epoch:    9/50    Loss: 3.695160277366638\n",
            "\n",
            "Epoch:    9/50    Loss: 3.7022221789360046\n",
            "\n",
            "Epoch:    9/50    Loss: 3.71167355966568\n",
            "\n",
            "Epoch:   10/50    Loss: 3.669304165582004\n",
            "\n",
            "Epoch:   10/50    Loss: 3.6339056301116943\n",
            "\n",
            "Epoch:   10/50    Loss: 3.6471871662139894\n",
            "\n",
            "Epoch:   10/50    Loss: 3.661983630657196\n",
            "\n",
            "Epoch:   10/50    Loss: 3.661674364566803\n",
            "\n",
            "Epoch:   10/50    Loss: 3.6635276465415956\n",
            "\n",
            "Epoch:   11/50    Loss: 3.634997607008064\n",
            "\n",
            "Epoch:   11/50    Loss: 3.6113018670082093\n",
            "\n",
            "Epoch:   11/50    Loss: 3.617585536956787\n",
            "\n",
            "Epoch:   11/50    Loss: 3.606170745372772\n",
            "\n",
            "Epoch:   11/50    Loss: 3.619485466003418\n",
            "\n",
            "Epoch:   11/50    Loss: 3.629741545677185\n",
            "\n",
            "Epoch:   12/50    Loss: 3.596336184288313\n",
            "\n",
            "Epoch:   12/50    Loss: 3.5807534584999083\n",
            "\n",
            "Epoch:   12/50    Loss: 3.5748008522987367\n",
            "\n",
            "Epoch:   12/50    Loss: 3.591181820869446\n",
            "\n",
            "Epoch:   12/50    Loss: 3.5943079891204834\n",
            "\n",
            "Epoch:   12/50    Loss: 3.594957181453705\n",
            "\n",
            "Epoch:   13/50    Loss: 3.5678856964617878\n",
            "\n",
            "Epoch:   13/50    Loss: 3.525797046661377\n",
            "\n",
            "Epoch:   13/50    Loss: 3.5504078726768493\n",
            "\n",
            "Epoch:   13/50    Loss: 3.566389437675476\n",
            "\n",
            "Epoch:   13/50    Loss: 3.5591121582984924\n",
            "\n",
            "Epoch:   13/50    Loss: 3.5652979216575624\n",
            "\n",
            "Epoch:   14/50    Loss: 3.5346364361273013\n",
            "\n",
            "Epoch:   14/50    Loss: 3.5013803849220277\n",
            "\n",
            "Epoch:   14/50    Loss: 3.524541504383087\n",
            "\n",
            "Epoch:   14/50    Loss: 3.5290094676017763\n",
            "\n",
            "Epoch:   14/50    Loss: 3.5392779030799866\n",
            "\n",
            "Epoch:   14/50    Loss: 3.538597540855408\n",
            "\n",
            "Epoch:   15/50    Loss: 3.503004463262042\n",
            "\n",
            "Epoch:   15/50    Loss: 3.4761958169937133\n",
            "\n",
            "Epoch:   15/50    Loss: 3.4978972692489623\n",
            "\n",
            "Epoch:   15/50    Loss: 3.5019329738616944\n",
            "\n",
            "Epoch:   15/50    Loss: 3.5117091927528383\n",
            "\n",
            "Epoch:   15/50    Loss: 3.5058995342254637\n",
            "\n",
            "Epoch:   16/50    Loss: 3.482272487129936\n",
            "\n",
            "Epoch:   16/50    Loss: 3.4375149459838865\n",
            "\n",
            "Epoch:   16/50    Loss: 3.4564506978988647\n",
            "\n",
            "Epoch:   16/50    Loss: 3.482343040943146\n",
            "\n",
            "Epoch:   16/50    Loss: 3.486496060371399\n",
            "\n",
            "Epoch:   16/50    Loss: 3.4918353552818298\n",
            "\n",
            "Epoch:   17/50    Loss: 3.4532720302293445\n",
            "\n",
            "Epoch:   17/50    Loss: 3.4183081364631653\n",
            "\n",
            "Epoch:   17/50    Loss: 3.448505756378174\n",
            "\n",
            "Epoch:   17/50    Loss: 3.4495038619041445\n",
            "\n",
            "Epoch:   17/50    Loss: 3.443812436103821\n",
            "\n",
            "Epoch:   17/50    Loss: 3.467635495185852\n",
            "\n",
            "Epoch:   18/50    Loss: 3.4282454265637345\n",
            "\n",
            "Epoch:   18/50    Loss: 3.396901589870453\n",
            "\n",
            "Epoch:   18/50    Loss: 3.401850646018982\n",
            "\n",
            "Epoch:   18/50    Loss: 3.4127060055732725\n",
            "\n",
            "Epoch:   18/50    Loss: 3.4272530999183655\n",
            "\n",
            "Epoch:   18/50    Loss: 3.4516045279502867\n",
            "\n",
            "Epoch:   19/50    Loss: 3.4033305625506394\n",
            "\n",
            "Epoch:   19/50    Loss: 3.385809368133545\n",
            "\n",
            "Epoch:   19/50    Loss: 3.3925083808898924\n",
            "\n",
            "Epoch:   19/50    Loss: 3.4029211750030517\n",
            "\n",
            "Epoch:   19/50    Loss: 3.3990299916267395\n",
            "\n",
            "Epoch:   19/50    Loss: 3.410096571922302\n",
            "\n",
            "Epoch:   20/50    Loss: 3.375196494169693\n",
            "\n",
            "Epoch:   20/50    Loss: 3.346540564060211\n",
            "\n",
            "Epoch:   20/50    Loss: 3.3662905440330504\n",
            "\n",
            "Epoch:   20/50    Loss: 3.387041004180908\n",
            "\n",
            "Epoch:   20/50    Loss: 3.3738479046821594\n",
            "\n",
            "Epoch:   20/50    Loss: 3.4122687487602232\n",
            "\n",
            "Epoch:   21/50    Loss: 3.3482947427478824\n",
            "\n",
            "Epoch:   21/50    Loss: 3.333741042137146\n",
            "\n",
            "Epoch:   21/50    Loss: 3.3409257655143736\n",
            "\n",
            "Epoch:   21/50    Loss: 3.3443410792350767\n",
            "\n",
            "Epoch:   21/50    Loss: 3.3757807579040526\n",
            "\n",
            "Epoch:   21/50    Loss: 3.361788733959198\n",
            "\n",
            "Epoch:   22/50    Loss: 3.3337589790920923\n",
            "\n",
            "Epoch:   22/50    Loss: 3.31763490486145\n",
            "\n",
            "Epoch:   22/50    Loss: 3.320863000869751\n",
            "\n",
            "Epoch:   22/50    Loss: 3.3244329390525817\n",
            "\n",
            "Epoch:   22/50    Loss: 3.350087788105011\n",
            "\n",
            "Epoch:   22/50    Loss: 3.3473986039161683\n",
            "\n",
            "Epoch:   23/50    Loss: 3.3187644618037284\n",
            "\n",
            "Epoch:   23/50    Loss: 3.2766707191467286\n",
            "\n",
            "Epoch:   23/50    Loss: 3.29940175819397\n",
            "\n",
            "Epoch:   23/50    Loss: 3.316064832687378\n",
            "\n",
            "Epoch:   23/50    Loss: 3.321264045238495\n",
            "\n",
            "Epoch:   23/50    Loss: 3.333601459503174\n",
            "\n",
            "Epoch:   24/50    Loss: 3.2921229908975325\n",
            "\n",
            "Epoch:   24/50    Loss: 3.2532665672302246\n",
            "\n",
            "Epoch:   24/50    Loss: 3.2878926854133605\n",
            "\n",
            "Epoch:   24/50    Loss: 3.2872069010734557\n",
            "\n",
            "Epoch:   24/50    Loss: 3.2921013631820677\n",
            "\n",
            "Epoch:   24/50    Loss: 3.3148726267814634\n",
            "\n",
            "Epoch:   25/50    Loss: 3.274784535260926\n",
            "\n",
            "Epoch:   25/50    Loss: 3.238859474182129\n",
            "\n",
            "Epoch:   25/50    Loss: 3.2626707911491395\n",
            "\n",
            "Epoch:   25/50    Loss: 3.275839111804962\n",
            "\n",
            "Epoch:   25/50    Loss: 3.2776507992744444\n",
            "\n",
            "Epoch:   25/50    Loss: 3.302740200996399\n",
            "\n",
            "Epoch:   26/50    Loss: 3.240494679625358\n",
            "\n",
            "Epoch:   26/50    Loss: 3.2298123712539675\n",
            "\n",
            "Epoch:   26/50    Loss: 3.239362087726593\n",
            "\n",
            "Epoch:   26/50    Loss: 3.255614839076996\n",
            "\n",
            "Epoch:   26/50    Loss: 3.2809023466110228\n",
            "\n",
            "Epoch:   26/50    Loss: 3.270399990081787\n",
            "\n",
            "Epoch:   27/50    Loss: 3.23609984663826\n",
            "\n",
            "Epoch:   27/50    Loss: 3.2142956867218015\n",
            "\n",
            "Epoch:   27/50    Loss: 3.225709285736084\n",
            "\n",
            "Epoch:   27/50    Loss: 3.242931001663208\n",
            "\n",
            "Epoch:   27/50    Loss: 3.248119511604309\n",
            "\n",
            "Epoch:   27/50    Loss: 3.2522699971199036\n",
            "\n",
            "Epoch:   28/50    Loss: 3.20738626914565\n",
            "\n",
            "Epoch:   28/50    Loss: 3.1942996420860292\n",
            "\n",
            "Epoch:   28/50    Loss: 3.194907109260559\n",
            "\n",
            "Epoch:   28/50    Loss: 3.218458310127258\n",
            "\n",
            "Epoch:   28/50    Loss: 3.229063036441803\n",
            "\n",
            "Epoch:   28/50    Loss: 3.2493028593063356\n",
            "\n",
            "Epoch:   29/50    Loss: 3.193884009360293\n",
            "\n",
            "Epoch:   29/50    Loss: 3.156938280105591\n",
            "\n",
            "Epoch:   29/50    Loss: 3.182319459915161\n",
            "\n",
            "Epoch:   29/50    Loss: 3.2099466857910155\n",
            "\n",
            "Epoch:   29/50    Loss: 3.2118870396614074\n",
            "\n",
            "Epoch:   29/50    Loss: 3.2281394634246827\n",
            "\n",
            "Epoch:   30/50    Loss: 3.1777576482088987\n",
            "\n",
            "Epoch:   30/50    Loss: 3.151027268409729\n",
            "\n",
            "Epoch:   30/50    Loss: 3.1731296172142027\n",
            "\n",
            "Epoch:   30/50    Loss: 3.183997721195221\n",
            "\n",
            "Epoch:   30/50    Loss: 3.1881611528396605\n",
            "\n",
            "Epoch:   30/50    Loss: 3.2086317014694212\n",
            "\n",
            "Epoch:   31/50    Loss: 3.164100260242622\n",
            "\n",
            "Epoch:   31/50    Loss: 3.1248540234565736\n",
            "\n",
            "Epoch:   31/50    Loss: 3.156491529941559\n",
            "\n",
            "Epoch:   31/50    Loss: 3.1586285972595216\n",
            "\n",
            "Epoch:   31/50    Loss: 3.181256310939789\n",
            "\n",
            "Epoch:   31/50    Loss: 3.184368919849396\n",
            "\n",
            "Epoch:   32/50    Loss: 3.1448378877084515\n",
            "\n",
            "Epoch:   32/50    Loss: 3.120074597835541\n",
            "\n",
            "Epoch:   32/50    Loss: 3.136263783931732\n",
            "\n",
            "Epoch:   32/50    Loss: 3.1465693249702453\n",
            "\n",
            "Epoch:   32/50    Loss: 3.1474016065597534\n",
            "\n",
            "Epoch:   32/50    Loss: 3.1789417514801026\n",
            "\n",
            "Epoch:   33/50    Loss: 3.1343340637491477\n",
            "\n",
            "Epoch:   33/50    Loss: 3.103865324020386\n",
            "\n",
            "Epoch:   33/50    Loss: 3.122282334804535\n",
            "\n",
            "Epoch:   33/50    Loss: 3.132474792957306\n",
            "\n",
            "Epoch:   33/50    Loss: 3.1430872354507446\n",
            "\n",
            "Epoch:   33/50    Loss: 3.1570709791183473\n",
            "\n",
            "Epoch:   34/50    Loss: 3.115242395751688\n",
            "\n",
            "Epoch:   34/50    Loss: 3.091464852809906\n",
            "\n",
            "Epoch:   34/50    Loss: 3.103531758785248\n",
            "\n",
            "Epoch:   34/50    Loss: 3.1268591799736023\n",
            "\n",
            "Epoch:   34/50    Loss: 3.136113076686859\n",
            "\n",
            "Epoch:   34/50    Loss: 3.1389244713783264\n",
            "\n",
            "Epoch:   35/50    Loss: 3.105268964241425\n",
            "\n",
            "Epoch:   35/50    Loss: 3.066754786014557\n",
            "\n",
            "Epoch:   35/50    Loss: 3.0788673057556153\n",
            "\n",
            "Epoch:   35/50    Loss: 3.1053509392738343\n",
            "\n",
            "Epoch:   35/50    Loss: 3.1083970918655397\n",
            "\n",
            "Epoch:   35/50    Loss: 3.137678036689758\n",
            "\n",
            "Epoch:   36/50    Loss: 3.093819075877625\n",
            "\n",
            "Epoch:   36/50    Loss: 3.048100170612335\n",
            "\n",
            "Epoch:   36/50    Loss: 3.0759284138679504\n",
            "\n",
            "Epoch:   36/50    Loss: 3.081340793132782\n",
            "\n",
            "Epoch:   36/50    Loss: 3.1089269552230836\n",
            "\n",
            "Epoch:   36/50    Loss: 3.1299550871849062\n",
            "\n",
            "Epoch:   37/50    Loss: 3.065995602369065\n",
            "\n",
            "Epoch:   37/50    Loss: 3.0449833002090454\n",
            "\n",
            "Epoch:   37/50    Loss: 3.073405725955963\n",
            "\n",
            "Epoch:   37/50    Loss: 3.0764306116104128\n",
            "\n",
            "Epoch:   37/50    Loss: 3.0877157244682314\n",
            "\n",
            "Epoch:   37/50    Loss: 3.099750993728638\n",
            "\n",
            "Epoch:   38/50    Loss: 3.0646430479250353\n",
            "\n",
            "Epoch:   38/50    Loss: 3.037539213180542\n",
            "\n",
            "Epoch:   38/50    Loss: 3.046882843017578\n",
            "\n",
            "Epoch:   38/50    Loss: 3.055253943443298\n",
            "\n",
            "Epoch:   38/50    Loss: 3.0900922498703003\n",
            "\n",
            "Epoch:   38/50    Loss: 3.0827087268829345\n",
            "\n",
            "Epoch:   39/50    Loss: 3.046075110050704\n",
            "\n",
            "Epoch:   39/50    Loss: 3.006762860298157\n",
            "\n",
            "Epoch:   39/50    Loss: 3.0352545609474184\n",
            "\n",
            "Epoch:   39/50    Loss: 3.0448403706550597\n",
            "\n",
            "Epoch:   39/50    Loss: 3.0706594486236574\n",
            "\n",
            "Epoch:   39/50    Loss: 3.075590932369232\n",
            "\n",
            "Epoch:   40/50    Loss: 3.029097335453053\n",
            "\n",
            "Epoch:   40/50    Loss: 3.0075903964042663\n",
            "\n",
            "Epoch:   40/50    Loss: 3.024348587036133\n",
            "\n",
            "Epoch:   40/50    Loss: 3.0293646368980407\n",
            "\n",
            "Epoch:   40/50    Loss: 3.047534194469452\n",
            "\n",
            "Epoch:   40/50    Loss: 3.0727292551994325\n",
            "\n",
            "Epoch:   41/50    Loss: 3.030594288754877\n",
            "\n",
            "Epoch:   41/50    Loss: 2.9965502104759216\n",
            "\n",
            "Epoch:   41/50    Loss: 3.0142821855545043\n",
            "\n",
            "Epoch:   41/50    Loss: 3.0306887516975403\n",
            "\n",
            "Epoch:   41/50    Loss: 3.038180902957916\n",
            "\n",
            "Epoch:   41/50    Loss: 3.044356524467468\n",
            "\n",
            "Epoch:   42/50    Loss: 3.009928898621385\n",
            "\n",
            "Epoch:   42/50    Loss: 2.9897102274894714\n",
            "\n",
            "Epoch:   42/50    Loss: 2.9886441044807435\n",
            "\n",
            "Epoch:   42/50    Loss: 3.010787911891937\n",
            "\n",
            "Epoch:   42/50    Loss: 3.0348994174003603\n",
            "\n",
            "Epoch:   42/50    Loss: 3.0384526615142824\n",
            "\n",
            "Epoch:   43/50    Loss: 3.0037136896150956\n",
            "\n",
            "Epoch:   43/50    Loss: 2.972703724861145\n",
            "\n",
            "Epoch:   43/50    Loss: 2.982114670753479\n",
            "\n",
            "Epoch:   43/50    Loss: 3.0052402386665342\n",
            "\n",
            "Epoch:   43/50    Loss: 3.0098897762298584\n",
            "\n",
            "Epoch:   43/50    Loss: 3.0291458435058596\n",
            "\n",
            "Epoch:   44/50    Loss: 2.992931171140583\n",
            "\n",
            "Epoch:   44/50    Loss: 2.9559627003669737\n",
            "\n",
            "Epoch:   44/50    Loss: 2.971362819671631\n",
            "\n",
            "Epoch:   44/50    Loss: 2.9950651335716247\n",
            "\n",
            "Epoch:   44/50    Loss: 3.008047780036926\n",
            "\n",
            "Epoch:   44/50    Loss: 3.0153395686149596\n",
            "\n",
            "Epoch:   45/50    Loss: 2.981771458644302\n",
            "\n",
            "Epoch:   45/50    Loss: 2.9486442766189573\n",
            "\n",
            "Epoch:   45/50    Loss: 2.9652510328292845\n",
            "\n",
            "Epoch:   45/50    Loss: 2.9876489939689637\n",
            "\n",
            "Epoch:   45/50    Loss: 2.9923869223594664\n",
            "\n",
            "Epoch:   45/50    Loss: 2.998680841445923\n",
            "\n",
            "Epoch:   46/50    Loss: 2.9683282175638825\n",
            "\n",
            "Epoch:   46/50    Loss: 2.936387547016144\n",
            "\n",
            "Epoch:   46/50    Loss: 2.962480968475342\n",
            "\n",
            "Epoch:   46/50    Loss: 2.9692856183052063\n",
            "\n",
            "Epoch:   46/50    Loss: 2.9868044476509095\n",
            "\n",
            "Epoch:   46/50    Loss: 2.997734359741211\n",
            "\n",
            "Epoch:   47/50    Loss: 2.9513942306448415\n",
            "\n",
            "Epoch:   47/50    Loss: 2.912522497177124\n",
            "\n",
            "Epoch:   47/50    Loss: 2.940717456817627\n",
            "\n",
            "Epoch:   47/50    Loss: 2.9668662929534912\n",
            "\n",
            "Epoch:   47/50    Loss: 2.9683426122665404\n",
            "\n",
            "Epoch:   47/50    Loss: 2.981028892993927\n",
            "\n",
            "Epoch:   48/50    Loss: 2.9472979853905743\n",
            "\n",
            "Epoch:   48/50    Loss: 2.90949019241333\n",
            "\n",
            "Epoch:   48/50    Loss: 2.935964705467224\n",
            "\n",
            "Epoch:   48/50    Loss: 2.945313533782959\n",
            "\n",
            "Epoch:   48/50    Loss: 2.9764597187042234\n",
            "\n",
            "Epoch:   48/50    Loss: 2.981620764732361\n",
            "\n",
            "Epoch:   49/50    Loss: 2.9479376741278767\n",
            "\n",
            "Epoch:   49/50    Loss: 2.90128666973114\n",
            "\n",
            "Epoch:   49/50    Loss: 2.9413450484275816\n",
            "\n",
            "Epoch:   49/50    Loss: 2.935579261302948\n",
            "\n",
            "Epoch:   49/50    Loss: 2.955124231338501\n",
            "\n",
            "Epoch:   49/50    Loss: 2.957662380218506\n",
            "\n",
            "Epoch:   50/50    Loss: 2.9272033043122025\n",
            "\n",
            "Epoch:   50/50    Loss: 2.8957440099716187\n",
            "\n",
            "Epoch:   50/50    Loss: 2.9188014521598817\n",
            "\n",
            "Epoch:   50/50    Loss: 2.9394107103347777\n",
            "\n",
            "Epoch:   50/50    Loss: 2.941805820465088\n",
            "\n",
            "Epoch:   50/50    Loss: 2.9615930728912354\n",
            "\n",
            "Model Trained and Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEzp_gvsgO7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}